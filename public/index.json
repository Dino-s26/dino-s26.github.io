[{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods running within the node\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods running within the Node are p\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically optional\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it allow\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules,\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules, services and communication, but this is entirely optional since we alreay have 3rd party add-ons like istio, traefik, and these days we have gateway\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 communication is\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node, but excluding DNS\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node, but excluding DN\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node such as\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node such as network routing,\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node such as network routing\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node such as network routing for services (Node IP, Cluster IP and )\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node and inside the node such as network routing for services (Node IP, Cluster IP, etc)\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this).\nSince we use CNI as current standard, Kube-Proxy just available there as optional to handle\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod communication\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod communication\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or available CNI\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or available Network Plugin to help the\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\n|||\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\n|Layer|||\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\n|Layer|Handle By||\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc ","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the pods will be use to\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle the\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD,\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI will try to make it compact and informative for everyone with little knowledge of Kubernetes understand how it work and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI will try to make it compact and informative for everyone with little knowledge of Kubernetes\nunderstand how it work and help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easy understanding can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works\nand help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easier to understand terminology can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works\nand help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easier to understand terminology can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works\nand help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easier to understand terminology can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\nWhat to see on next part ? I hope my Part-2 writing series of Self-host Kubernetes can help you (and also myself) learn more about kubernetes deeper. Next part I will post about how to host it in your local machine and what are the things you need to prepare in-order to host it properly.\nDont worry I will not host it on AWS or other Cloud Platform \u0026#x1f609;\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works\nand help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"},{"content":"Intermezzo Howdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\nBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand the base components of how Kubernetes work and how it will interract each other within the cluster or just single instance of Kubernetes\nI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works and help them to catch up quickly with some of terminology that I will use within my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\nVirtualization vs Containerization In Traditional Deployment term, what we know when setup application is that, we will have followings:\nHardware (1 hardware can host multiple application or multiple hardware can host multiple application ) OS (it can be vary and become problem in the future) APP with multiple dependencies (each App will have different dependencies and OS and/or Hardware compatibility) Within Virtualization, what differentiate it from Traditional way of deploying application as followings:\nVM\u0026rsquo;s (Virtual Machine) will be host under hypervisor which can run virtualization, it can be same it can be different hypervisor VM\u0026rsquo;s still require OS and dependencies to run, and Application will run within the VM not the hypervisor Virtualization utilize scalability of physical hardware to isolate each VM\u0026rsquo;s while also utilize the Hardware, which shared accross VM\u0026rsquo;s what about Container ?\nIn container, the only different to virtualization as follows:\nContainer remove Hypervisor Layer and directly interact with the Host OS, let\u0026rsquo;s say you install docker on linux it will automatically use linux container runtime, in windows it is kind of different because you\u0026rsquo;re using windows runtime to run linux container but it is also possible to run windows container on it, I will not deep dive this as this is out of the scope for now Container not really require OS to host the APP, but it will interact with the app image that are compiled under the container runtime we use (CMIIW, it\u0026rsquo;s been while I learn container terminology so pardon my explanation here) Lastly Container will still need dependencies but it will tailor to the image we use Summary Reference source\nThe Main Menu \u0026hellip; Kubernetes Core Component Let\u0026rsquo;s jump into the Core Component of the Kubernetes. As we self-host our Kubernetes Cluster the main component we need to aware are \u0026ldquo;Control Plane/s\u0026rdquo; and \u0026ldquo;Node/s\u0026rdquo;\nControl Plane Basically Control Plane are the brain of K8s cluster, where it manage all the communication of it is Data Plane (Node/s), there are several compoenent within Control Plane we need to understand how it work, followings are the Control Plane components:\nkube-apiserver Kube API Server are the core component that expose Kubernetes HTTP API to be able to communicate outside of K8s Cluster. This core component will handle all the request such as kubectl command and the communication of the request coming into K8s cluster.\netcd ETCD are persistent database that keeping track of all the changes happen inside the K8s cluster. Usually in big cluster it will use ETCD, but on smaller deployment can use sqlite or dqlite depending on the needs and requirement.\nkube-scheduler Kube Scheduler are the component that communicate between Kube API Server and the Node/s, in this case the scheduler will oversees the spawn of Pod/s that will be deployed to the Node/s, this also will taken some factors such as: individual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.\nkube-control-manager Lastly Kube Control Manager that will oversees the high level of K8s cluster, which mean the overall process happen inside the control plane.\nFor example:\nNode Controller, this will oversees the Node/s scale-up or scale-down and also keep track of the keep Alive of the nodes\nJob Controller, this will oversees the CronJob that happen within the K8s cluster, which also track the success and fail state of the job\nabove are just example, but only giving how the Kube control Manager work in general\nNode (Data Plane) Node or we can just straightly say Data Plane, are the part where kubernetes deploy it is services like pods, ingress, persistent-volume, etc. There are also couple component within the Node (Data Plane) such as:\nKubelet Kubelet are basically the component where it communicate with the node and also the Kubernetes control-plane API, which ensure the Pods and it is container or side-car container run properly within the node.\nKube-Proxy Kube-Proxy are basically the component where it maintain network rules and communication within or inter-node communication. This mean only including L4 (TCP/UDP) communication is use within the node (intern-node) and inside the node such as network routing for services (Node IP, Cluster IP, etc), but excluding the pod-to-pod DNS communication, only service-to-pod communication (please cmiiw on this, still kind of lost sometimes).\nSince we use CNI to handle pod-to-pod IP communication which will communicate with the Kube-Proxy or other available network plugin.\nfor easier to understand terminology can refer to this table below\nLayer Handle By Role as L2/L3 CNI Pod-to-pod networking L4 kube-proxy Service-level load balancing L7 Ingress/Mesh App-aware routing, TLS, etc Container Runtime Container runtime are the underlay which pods / container within the node will be use to run the containers effectively and handle it is lifecycle and execution of the containers.\nWithin kubernetes, it will use container runtime like Docker, ContainerD, CRI-O, and other that supported by kubernetes.\nWhat to see on next part ? I hope my Part-2 writing series of Self-host Kubernetes can help you (and also myself) learn more about kubernetes deeper. Next part I will post about how to host it in your local machine and what are the things you need to prepare in-order to host it properly.\nDont worry I will not host it on AWS or other Cloud Platform \u0026#x1f609;, and see you on my next post.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt2/self-host-kubernetes-pt2.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;, and welcome back to second part of self-host kubernetes !\u003c/p\u003e\n\u003cp\u003eBefore jump to the cluster setup and all the technical thingy, it\u0026rsquo;s better to understand\nthe base components of how Kubernetes work and how it will interract\neach other within the cluster or just single instance of Kubernetes\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ll try to keep it compact and informative, so that people with little knowledge of Kubernetes can understand how it works\nand help them to catch up quickly with some of terminology that I will use\nwithin my posts (there will be lot\u0026rsquo;s of part to deep dive into Kubernetes)\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.2"},{"content":"Intermezzo Howdy \u0026#x1f920; Been while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster. Yes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work I got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\nPreface Before jump right at the topic, let\u0026rsquo;s familiarize with K8s also known as Kubernetes.\nif you new to the K8s or Kubernetes, here are the short summary of what is it \u0026hellip;\nQuoted from: Google and also Kubernetes web\nKubernetes also known as (K8s in short) are open-source container orchestration system to automate the deployment of application, scalling and also it is management. Originally design by Google employee then continously maintained by CNCF (Cloud Native Computing Foundation) under Linux Foundation. Then what\u0026rsquo;s make it different from Docker Swarm ? Good question actually, the simple answer to it is how big is your application. Docker Swarm are meant to be simple, small, lightweight and easy to setup at your disposal, but it depend on Docker API container runtime\nMeanwhile for Kubernetes, if you have multiple micro-service architechture which need to be meshed with other services, Lage scale, have capability of self-healing and also support multiple container runtime API (not just Docker API, can be containerd, CRI-O, etc), then kubernetes is your choices for this.\nBut to be fair, imo using kubernetes not always the best solution for your application \u0026#x1f604;, so back again to the needs.\nWhy self-host my own kubernetes cluster ? Back to the main question, as we already get the bare minimum of knowledge of Kubernetes \u0026hellip;\nWHY ?\nThe simple answer I can come up with it are:\nI\u0026rsquo;m kind of person who have high curiosity of tech Familiarize myself with kubernetes tech stack Preparing CKA Exam in the future Have lab to do experimental and also danger things that can\u0026rsquo;t be done on manage service kubernetes (I really don\u0026rsquo;t want to mess up and get in trouble for it \u0026#x1f609; on company property haha) Pre-look of the setup I create As this post already get too long, this will be end of Part-1, I will talk the technical stuff on next part of my post.\nBefore I close this, here\u0026rsquo;s are the look of my Kubernetes Cluster Setup to you can have the idea what it\u0026rsquo;s look like in logical term.\n","permalink":"http://localhost:1313/posts/may-25/self-host-k8s-cluster-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/may-25/self-host-kubernetes-pt1/self-host-kubernetes-pt1.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHowdy \u0026#x1f920;\nBeen while I didn\u0026rsquo;t update my post here, so in this post I will update my journey on self-host my kubernetes cluster.\nYes you heard it right, since I got exposure to Kubernetes (also known as K8s in short) from EKS (Elastic Kubernetes Service by AWS) from my previous work\nI got weird idea to fullfill my hands-on experience to learn more on K8s, also preparing myself if I change my mind in the future to get CKA certification.\u003c/p\u003e","title":"Self-host Kubernetes Cluster Pt.1"},{"content":"Intermezzo In this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\nDisclaimer Let me put \u0026ldquo;Disclaimer\u0026rdquo; first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on Vantage that have been integrated to get detail costs from both Cloud Platform.\nHere\u0026rsquo;s what cost me during my migration from GCP to AWS So monthly I usually spend around ~150k IDR to ~350k IDR for GCP Cloud Storage cost. So This cost actually is based on Storage Class and operation I do within the GCP Cloud Storage, you can see the breakdown as follows:\n[GCP Storage Class Breakdown]\nAs a note, the standard class cost increase do to my migration data. TL;DR, my data are inside Archive Class and Nearline Class, which I need to change the class to Standard Class inorder to move the data without adding additional cost, also the data was stored in Singapore Region \u0026#x1f622;.\nPS: Ignore November 2024 here as the data not yet consolidated\n[GCP Cost Billing]\nMoving on \u0026hellip; here\u0026rsquo;s the total billing each month I pay (Converted to $, for AWS Cost Comparison) \u0026hellip; As we can see this is all the cost I have to pay during my data migration from GCP Cloud Storage to AWS S3 \u0026hellip;\nThe spike in price is expected as we change the storage class and download data during the migration.\n","permalink":"http://localhost:1313/posts/nov-24/moving-data-gcp-to-aws-s3-pt3/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Intermezzo\" loading=\"lazy\" src=\"/img/nov-24/moving-data-gcp-to-aws-s3-pt3/mr-krab-money.png\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eIn this part I will update regarding the Cost I spend for store most of my data in AWS S3 since I move 90% of my backup from GCP Cloud Storage \u0026#x1f613; \u0026hellip;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eLet me put \u003cstrong\u003e\u0026ldquo;Disclaimer\u0026rdquo;\u003c/strong\u003e first, since this is still my ongoing project to deprecate GCP Cloud Storage, the cost here is what I can present based on the data I gather and process on \u003ca href=\"https://vantage.sh\"\u003eVantage\u003c/a\u003e that have been integrated to get detail costs from both Cloud Platform.\u003c/p\u003e","title":"How much cost did I save by moving to AWS S3 ? Pt.3"},{"content":"Intermezzo Henlo, back again \u0026hellip; Been a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3. much already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\nbut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have then I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\nThe Main Experiences Stuff \u0026hellip; Things to Prepare: New EC2 Instance, I Suggest have it pair with 500GB EBS (as minimum, depend on how much data you will migrate) in a different partition from the root partition. New S3 Bucket. AWS CLI and GCP SDK installed on New EC2 instance New IAM Role for New EC2 Instance to access new S3 Bucket Make sure the GCP Cloud Storage are in \u0026ldquo;Standard Class\u0026rdquo; or else it will incur really expensive price when migrated. Illustration on what it should look like \u0026hellip; Here\u0026rsquo;s the setup I do to migrate the data from GCP Cloud Storage to AWS S3\nand here\u0026rsquo;s some quick explanation on the flow of what I do here:\nCreated new EC2 instance which have 32GB Root Partition and 500GB EBS Storage mounted as separated partition for temporarily store my data from GCP Cloud Storage. Install AWS CLI and GCP SDK on the EC2 Instance and configure it properly. Download data from GCP Cloud Storage to the EBS Partition, this process takes time and several batch. Once data is ready, Upload to the AWS S3 Bucket in batch, this also takes time to process. Repeat steps 3 - 4, until all the data or partial of the data is migrated. Done Pretty straight forward isn\u0026rsquo;t ?, yes and no actually \u0026#x1f605; \u0026hellip; Let\u0026rsquo;s Deep dive a bit \u0026hellip;\nA little bit deep dive Previously I said it is straight forward process, but there is catches here which I\u0026rsquo;m willing to explain a bit why\nMigrating the data from GCP Cloud Storage to AWS S3 are a bit costly, as you can see from the capture below (the 3 spike bars) this is how much it cost for me to migrate (refer to the total cost) data from GCP Cloud Storage to AWS S3 from December 2023 to January 2024 \u0026#x1f972;, converted to USD + Taxes are around $106. Actually not that much, but if it is for personal usage it really cost you fortune, especially if you are conservative with your own budget. The reason why it is costly because at the time the data on GCP Cloud Storage are stored as Archival Storage Class Type, and I forgot to convert the objects into Standard Class Type Storage for the objects that are stored more than 1 year in the Cloud Storage. Transfering around ~4459 Objects are no easy job \u0026#x1f605;, it need to be done in batches (Spoiler: I use multiple tmux session to batch the process). Capture shown below are majority larger Object Data I\u0026rsquo;ve already migrated to AWS S3 so far, as it related to point number 1 above I still have data left to be migrated to AWS S3, but I still haven\u0026rsquo;t have time to continue the work. Cost wise, it is not far from GCP Cloud Storage. I\u0026rsquo;m not sure why it is bit expensive on AWS S3 at this moment, but compared the usage from Sep-23 to Nov-23 on GCP Cloud Storage the cost spend on GCP are less than what already spend on AWS S3 on Jan-24 to Mar-24 (Prorated). Note: Using this range of date as it is more accurate data for non-operational cloud storage operation [AWS S3 Jan-24 to Mar-24 (Prorated)] [GCP Cloud Storage Sep-23 to Nov-23 for comparison] End of Part-2 That\u0026rsquo;s a little bit of deep dive of what happen during the migration of the data from GCP Cloud Storage to AWS S3 will continue in the next part for the technical stuff\nPart-1, Why I\u0026rsquo;m moving to AWS S3 Pt.1 TBD Part-3 ","permalink":"http://localhost:1313/posts/mar-24/moving-data-gcp-to-aws-s3-pt2/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo, back again \u0026hellip;\nBeen a while I haven\u0026rsquo;t write the continuation of this story of how I\u0026rsquo;m moving my data from GCP Cloud Storage to AWS S3.\nmuch already happen, this and that don\u0026rsquo;t really want to go into detail but here I\u0026rsquo;m back \u0026hellip;\u003c/p\u003e\n\u003cp\u003ebut before begin, sorry for not posting but I will try to make post about anything for now atleast once a month, if I dont have\nthen I don\u0026rsquo;t really have something to post at the moment and probably busy with my new job \u0026#x1f613;.\u003c/p\u003e","title":"How I'm moving to AWS S3 Pt.2"},{"content":"Intermezzo You guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS which somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife, which is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\nNow in reality (2024 Earth Year), we realize that Tech is growing so fast that we didn\u0026rsquo;t even see what kind of tech is coming, it is just there. Honestly I kind of scared at the moment with current Tech growth especially with AI stuff (aka Skynet, 2001: A Space Odyssey, Rouge AI, etc), but there\u0026rsquo;s new company called \u0026lsquo;rabbit\u0026rsquo;, yes you hear it right.\nTL;DR, The company is releasing companion device called \u0026ldquo;R1\u0026rdquo; which not phone, just companion device with it is own OS, now here\u0026rsquo;s the summary of what I learn from the product keynotes.\nLAM (Large Action Model) Usually we hear about LLM, but for \u0026ldquo;Rabbit OS\u0026rdquo; they use term LAM (Large Action Model). In short, LAM more on how the OS will interact with various of system interface, learn it, and also act like human to interaction with it, so it is not going to replace our current phone in general.\nTL;DR, How LAM work are in 3 ways, Intention, Interface, Interact.\nIntention By this mean LAM will try to understand what human perceiving so the LAM will need to learn from the prompt given by us.\nInterface By this mean LAM will learn our app interface, either it is android or ios, LAM will learn the interface of the app and get used to it to understand our prompt.\nInteract By this mean LAM will interact with us directly from the device, all we care wether the prompt we give is correct or not.\nRabbit R1 In Brief R1, is not look like Phone or any other smart devices we usually see, but more like simplified version of handheld device, remind me of pager with limited functionality.\nFor Technical Specs can be seen here\nDiving deep to the R1 Companion device schematic, as we can see it is really compact and easily to be hold with 1 hand. Not much for a companion device, since the device itself will be activated by voice command, it really doesn\u0026rsquo;t need to have bigger screen.\nBut there is a catch here, the LAM capability still limited in some cases as follows:\nSince the Keynote Launch, Rabbit R1 is expected to be shipped in US/Canada by March/April 2024 other than that will be estimated later 2024. Another catch here is that the Pre-order itself still limited to couples of country, even in Asia only Japan and South Korea havto e the privilege for the shipment, thought Singapore should be in the qualification but turn out it is not.\nThe biggest part where it is interesting is the Price of the device itself. As stated in the Keynote Launch by the CEO, Jesse Lyu, the price is $199 + taxes (+ shipping cost for international shipment) and without any subscription what so ever, interesting isn\u0026rsquo;t ?.\nKey take way Since the R1 companion device still in Pre-order phase, it will take while before we see it adopt by most of people around the world. I kind of looking forward when they will open more shipment, especially Indonesia to do the hands-on and try their feature, also price wise it is still reachable for most of the people. Like it is stated in Keynotes, it ain\u0026rsquo;t Phone or other smart devices, but more to companion device which we still need our phone for another purpose. Also, looking for what other use cases will it be possible, like block spam call, or we can do live translation for our call, or anything else.\nReferences:\nhttps://www.rabbit.tech/ https://arc.net/l/quote/hzdvclrp ","permalink":"http://localhost:1313/posts/feb-24/is-her-become-reality/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eYou guys remember there\u0026rsquo;s movie called \u0026ldquo;HER\u0026rdquo;, where the protagonis Theodore Twombly the introvert letter writer decide to buy OS1, an AI first OS\nwhich somehow Theodore become attached to the AI. While he try to understand the AI (aka Samantha), he also going through divorce with his wife,\nwhich is sad but somehow, day by day Theodore become attached to Samantha until one day Samantha become self aware and then it leave Theodore.\u003c/p\u003e","title":"Is 'HER' become reality ?, R1 Companion Device"},{"content":"Intermezzo Henlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\nSo, actually long story short \u0026hellip; I\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate in cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\nUntil recently I learn AWS Cloud Stack Tech, which way more simplified and also integration with their CLI tools more seamless, GCP CLI is not that bad, I just rarely use it, unlike AWS CLI since my work related to AWS Stacks\nThe \u0026lsquo;Why moving to AWS S3\u0026rsquo; even tho I realize that my bill for GCP Cloud Storage are around ~$50/month with Indonesia Tax around 11% (used to 10%, since the changes with Indonesia Tax Rules in the past), this is way cheaper tbh for me, but there are couple of stuff makes me realize that I want to move to AWS S3 for some reasons (Which in this matter are subjective to my own oppinion):\nAWS S3 can provide me with granular dashboard where I can see how much data I have, for comparison here\u0026rsquo;s how the dashboard looks GCP Cloud Storage Dashboard Side notes: even tho we can customize the dashboard, it doesn\u0026rsquo;t have build in dashboard to see the data we look for (e.g. Storage/ objects sizes), which become problematic and somehow not really in favor for me to check how much Data I have in my Cloud Storage\nAWS S3 Dashboard S3 provide more robust API (CRR, Object Tagging, ) Even to I not using CRR (Cross Region Replication) for now, but I\u0026rsquo;m planned to use it in the future. So if in the future I decide to moving somewhere I could just replicate the data to the nearest region to access my data.\nOther than that, I usually use Cyberduck to access data, so in the event I need to access some data (e.g. download / upload) I could just do it seamlessly\nGranular IAM to the level of it is objects To be fair, It is really tricky to share files in Cloud Storage. Not saying it is hard but it needs extra steps in order to share files, especially if the files itself is in bigger sizes like GBs of files, also we need to do it via gcloud / gsutil in order to create the signed-URL in GCP Cloud Storage.\nCompare with S3 we can just create the signed-URL directly from AWS Console, which I realize it would be easier for me when I decide to transfer knowledge in form of recording files that are big and need times to download \u0026#x1f606;.\nThe Pros and Cons of AWS S3 Honestly, moving from GCP Cloud Storage to AWS S3 give me some impression of pros and cons I will need to deal with the rest of my life time using the services \u0026hellip;\nPros :\nMore Mature Product (personally) More secure with IAM control level, even to the object itself Work flawlessly with aws-cli, as long as you have the right permissions, which kind of help when I want to access the data from EC2 instances directly More advance and have it is case by case, even migrating data from 2 different AWS account can be done easily More cheaper per GB pricing the first 50 TB Data, which around $ ~0.0025/GB, compared GCP Cloud Storage around $ ~0.020/GB, the detail can be checked here There will be no Data Transfer charge if you transfer between EC2 or other AWS Services You can export list of the data from AWS S3 Bucket into inventory reports, with a bit configuration here Cons :\n\u0026ldquo;There are per-request ingest charges when using PUT, COPY, or lifecycle rules to move data into any S3 storage class\u0026rdquo;, this is from official AWS S3 Page, which kind of bummer for me, compared to GCP Cloud Storage which still free for standard class storage \u0026#x1f603; By defult AWS S3 access are private, be sure to change it accordingly whenever convenient It is bit advance at first so take your time to adjust and learn it, dont worry you wont be charge until you put data on it (cmiiw on this) AWS Free Tier with 5GB only the first 12 Month you use AWS S3, after that you\u0026rsquo;ll be charge End of Part-1 Since it is to long to put into 1 post, I will break it down into couple of parts\nPart-2, How I\u0026rsquo;m moving to AWS S3 Pt.2 TBD Part-3 ","permalink":"http://localhost:1313/posts/jan-24/moving-data-gcp-to-aws-s3-pt1/","summary":"\u003ch2 id=\"intermezzo\"\u003eIntermezzo\u003c/h2\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eHenlo and Happy New Year 2024, I hope you guys in healthy condition and still have lots to achieve this year \u0026#x1f601;\u003c/p\u003e\n\u003cp\u003eSo, actually long story short \u0026hellip;\nI\u0026rsquo;m actually GCP person since 2018/2019, the first time I ever learn Cloud Tech and also getting my first certificate\nin cloud, even tho it is still associate level lol. By that time I\u0026rsquo;m getting used to using GCP as my primary Cloud Stacks\u003c/p\u003e","title":"Why I'm moving to AWS S3 Pt.1"},{"content":"First Post ! Thanks for visiting, currently it is empty, and I put this as placeholder. I plan to have upcoming post later on, but still busy with my works, be sure to stay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\n","permalink":"http://localhost:1313/posts/nov-23/hello-world/","summary":"\u003ch3 id=\"first-post-\"\u003eFirst Post !\u003c/h3\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eThanks for visiting, currently it is empty, and I put this as placeholder.\nI plan to have upcoming post later on, but still busy with my works, be sure to\nstay tuned with updates on my web / blog / or whatever you call it today \u0026#x1f604;\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Hello World !"}]